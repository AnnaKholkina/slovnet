{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!mkdir -p data rubert model\n",
    "s3 = S3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/taiga/Fontanka.tar.gz -P data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/ods/gazeta_v1.csv.zip -P data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/ods/interfax_v1.csv.zip -P data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/lenta-ru-news.csv.gz -P data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/buriy/news-articles-2014.tar.bz2 -P data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/buriy/news-articles-2015-part1.tar.bz2 -P data/raw\n",
    "# !wget https://storage.yandexcloud.net/natasha-corus/buriy/news-articles-2015-part2.tar.bz2 -P data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADS = {\n",
    "#     'gazeta_v1.csv.zip': load_ods_gazeta,\n",
    "#     'interfax_v1.csv.zip': load_ods_interfax,\n",
    "#     'Fontanka.tar.gz': load_taiga_fontanka,\n",
    "#     'lenta-ru-news.csv.gz': load_lenta,\n",
    "#     'news-articles-2015-part1.tar.bz2': load_buriy_news,\n",
    "#     'news-articles-2015-part2.tar.bz2': load_buriy_news,\n",
    "#     'news-articles-2014.tar.bz2': load_buriy_news,\n",
    "# }\n",
    "\n",
    "\n",
    "# lines = []  # Requires 15Gb RAM\n",
    "# for name in listdir('data/raw'):\n",
    "#     path = 'data/raw/' + name\n",
    "#     records = LOADS[name](path)\n",
    "#     for record in log_progress(records, desc=name):\n",
    "#         line = re.sub('\\s+', ' ', record.text)\n",
    "#         lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed(1)\n",
    "# shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = 1000\n",
    "# dump_lines(lines[:cap], 'data/test.txt')\n",
    "# dump_lines(log_progress(lines[cap:]), 'data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3.upload('data/test.txt', '01_bert_news/data/test.txt')\n",
    "# s3.upload('data/train.txt', '01_bert_news/data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('data/test.txt'):\n",
    "    s3.download('01_bert_news/data/test.txt', 'data/test.txt')\n",
    "    s3.download('01_bert_news/data/train.txt', 'data/train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = CUDA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists('rubert/vocab.txt'):\n",
    "    for name in ['vocab.txt', 'emb.pt', 'encoder.pt', 'mlm.pt']:\n",
    "        s3.download('01_bert_news/rubert/' + name, 'rubert/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(load_lines('rubert/vocab.txt'))\n",
    "vocab = BERTVocab(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BERTConfig(\n",
    "    vocab_size=50106,\n",
    "    seq_len=512,\n",
    "    emb_dim=768,\n",
    "    layers_num=12,\n",
    "    heads_num=12,\n",
    "    hidden_dim=3072,\n",
    "    dropout=0.1,\n",
    "    norm_eps=1e-12\n",
    ")\n",
    "emb = BERTEmbedding(\n",
    "    config.vocab_size, config.seq_len, config.emb_dim,\n",
    "    config.dropout, config.norm_eps\n",
    ")\n",
    "emb.position.requires_grad = False  # fix pos emb to train on short seqs\n",
    "encoder = BERTEncoder(\n",
    "    config.layers_num, config.emb_dim, config.heads_num, config.hidden_dim,\n",
    "    config.dropout, config.norm_eps\n",
    ")\n",
    "mlm = BERTMLMHead(config.emb_dim, config.vocab_size)\n",
    "model = BERTMLM(emb, encoder, mlm)\n",
    "\n",
    "load_model(model, dir='rubert')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = BERTMLMEncoder(\n",
    "    vocab,\n",
    "    seq_len=128,\n",
    "    batch_size=32,\n",
    "    shuffle_size=10000\n",
    ")\n",
    "\n",
    "lines = load_lines('data/test.txt')\n",
    "batches = encode(lines)\n",
    "test_batches = [_.to(device) for _ in batches]\n",
    "\n",
    "lines = load_lines('data/train.txt')\n",
    "batches = encode(lines)\n",
    "train_batches = (_.to(device) for _ in batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board('03', 'runs')\n",
    "train_board = board.section('01_train')\n",
    "test_board = board.section('02_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level='O2')\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb95bcf426d486e9f04bb1a03985427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1048576.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1048576.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1048576.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4194304.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2097152.0\n"
     ]
    }
   ],
   "source": [
    "train_meter = MLMScoreMeter()\n",
    "test_meter = MLMScoreMeter()\n",
    "\n",
    "accum_steps = 64  # 2K batch\n",
    "log_steps = 256\n",
    "eval_steps = 512\n",
    "save_steps = eval_steps * 10\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for step, batch in log_progress(enumerate(train_batches)):\n",
    "    batch = process_batch(model, criterion, batch)\n",
    "    batch.loss /= accum_steps\n",
    "    \n",
    "    with amp.scale_loss(batch.loss, optimizer) as scaled:\n",
    "        scaled.backward()\n",
    "\n",
    "    score = score_batch(batch, ks=())\n",
    "    train_meter.add(score)\n",
    "\n",
    "    if every(step, log_steps):\n",
    "        train_meter.write(train_board)\n",
    "        train_meter.reset()\n",
    "\n",
    "    if every(step, accum_steps):\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if every(step, eval_steps):\n",
    "            batches = infer_batches(model, criterion, test_batches)\n",
    "            scores = score_batches(batches)\n",
    "            test_meter.extend(scores)\n",
    "            test_meter.write(test_board)\n",
    "            test_meter.reset()\n",
    "    \n",
    "    if every(step, save_steps):\n",
    "        dump_model(model)\n",
    "        upload_model(s3)\n",
    "            \n",
    "    board.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
